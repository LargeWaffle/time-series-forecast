{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Time series forecasting\n",
    "## Imports"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from statistics import mean\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score, mean_squared_log_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:41:13.688784Z",
     "iopub.execute_input": "2023-06-22T13:41:13.689130Z",
     "iopub.status.idle": "2023-06-22T13:41:13.694376Z",
     "shell.execute_reply.started": "2023-06-22T13:41:13.689105Z",
     "shell.execute_reply": "2023-06-22T13:41:13.693555Z"
    },
    "trusted": true
   },
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Global variables and read data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "DATAPATH = \"/kaggle/input/store-sales-time-series-forecasting\"\n",
    "# DATAPATH = \"data/store-sales\"\n",
    "FIGSIZE = (14, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:05.273398Z",
     "iopub.execute_input": "2023-06-22T13:33:05.273742Z",
     "iopub.status.idle": "2023-06-22T13:33:05.277994Z",
     "shell.execute_reply.started": "2023-06-22T13:33:05.273711Z",
     "shell.execute_reply": "2023-06-22T13:33:05.277204Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_df = pd.read_csv(DATAPATH + '/train.csv',\n",
    "                       usecols=['id', 'store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n",
    "                       dtype={\n",
    "                           'id': 'uint32',\n",
    "                           'store_nbr': 'int32',\n",
    "                           'family': 'string',\n",
    "                           'sales': 'float32',\n",
    "                           'onpromotion': 'uint32',\n",
    "                       },\n",
    "                       parse_dates=['date'])\n",
    "\n",
    "test_df = pd.read_csv(DATAPATH + '/test.csv',\n",
    "                      dtype={\n",
    "                          'id': 'uint32',\n",
    "                          'store_nbr': 'int32',\n",
    "                          'family': 'string',\n",
    "                          'onpromotion': 'uint32',\n",
    "                      },\n",
    "                      parse_dates=['date'])\n",
    "\n",
    "stores_df = pd.read_csv(DATAPATH + '/stores.csv',\n",
    "                        dtype={\n",
    "                            'store_nbr': 'int32',\n",
    "                            'city': 'string',\n",
    "                            'state': 'string',\n",
    "                            'type': 'string',\n",
    "                            'cluster': 'int32',\n",
    "                        })\n",
    "\n",
    "stores_df = stores_df.rename(columns={'type': 'store_type'})\n",
    "\n",
    "transactions_df = pd.read_csv(DATAPATH + '/transactions.csv',\n",
    "                              dtype={\n",
    "                                  'store_nbr': 'int32',\n",
    "                                  'transactions': 'uint32'\n",
    "                              },\n",
    "                              parse_dates=['date'])\n",
    "\n",
    "oil_df = pd.read_csv(DATAPATH + '/oil.csv',\n",
    "                     dtype={'dcoilwtico': 'float32'},\n",
    "                     parse_dates=['date'])\n",
    "\n",
    "holidays_df = pd.read_csv(DATAPATH + '/holidays_events.csv',\n",
    "                          dtype={\n",
    "                              'type': 'string',\n",
    "                              'locale': 'string',\n",
    "                              'locale_name': 'string',\n",
    "                              'description': 'string',\n",
    "                              'transferred': 'bool',\n",
    "                          },\n",
    "                          parse_dates=['date'])\n",
    "holidays_df = holidays_df.rename(columns={'type': 'holiday_type'})\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:05.279187Z",
     "iopub.execute_input": "2023-06-22T13:33:05.279644Z",
     "iopub.status.idle": "2023-06-22T13:33:06.932689Z",
     "shell.execute_reply.started": "2023-06-22T13:33:05.279623Z",
     "shell.execute_reply": "2023-06-22T13:33:06.932028Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# variables permettant de créer les ensembles de modèles\n",
    "\n",
    "nb_outsamples = test_df['date'].nunique()\n",
    "nb_stores = train_df['store_nbr'].nunique()\n",
    "nb_families = train_df['family'].nunique()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:06.934389Z",
     "iopub.execute_input": "2023-06-22T13:33:06.934949Z",
     "iopub.status.idle": "2023-06-22T13:33:07.124466Z",
     "shell.execute_reply.started": "2023-06-22T13:33:06.934928Z",
     "shell.execute_reply": "2023-06-22T13:33:07.123117Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def remove_outliers(df):\n",
    "    \"\"\"\n",
    "    Retire les valeurs extrêmes causées par le tremblement de terre\n",
    "    \"\"\"\n",
    "    val = df.sales.quantile(0.99)\n",
    "    df = df.drop(df[df.sales > val].index)\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = remove_outliers(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:07.125558Z",
     "iopub.execute_input": "2023-06-22T13:33:07.125845Z",
     "iopub.status.idle": "2023-06-22T13:33:07.382299Z",
     "shell.execute_reply.started": "2023-06-22T13:33:07.125820Z",
     "shell.execute_reply": "2023-06-22T13:33:07.380979Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def assign_time_ft(df):\n",
    "    \"\"\"\n",
    "    Assigne les features calendaires, temporelles, etc.\n",
    "    \"\"\"\n",
    "    dt_index = df['date'].dt\n",
    "\n",
    "    df['day'] = dt_index.day\n",
    "    df['payday'] = ((dt_index.day == 15) | dt_index.is_month_end).astype('int')\n",
    "    df['dayofweek'] = dt_index.day_of_week.astype('int')\n",
    "    df[\"dayofyear\"] = dt_index.dayofyear\n",
    "    df['weekday'] = dt_index.weekday\n",
    "    df['month'] = dt_index.month\n",
    "    df['month_end'] = dt_index.is_month_end.astype('int')\n",
    "\n",
    "    df['year'] = dt_index.year\n",
    "    df['newyear'] = df[\"dayofyear\"] == 1\n",
    "\n",
    "    df['startschool'] = dt_index.month.isin((4, 5, 8, 9))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = assign_time_ft(train_df)\n",
    "test_df = assign_time_ft(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:07.383504Z",
     "iopub.execute_input": "2023-06-22T13:33:07.383785Z",
     "iopub.status.idle": "2023-06-22T13:33:08.212325Z",
     "shell.execute_reply.started": "2023-06-22T13:33:07.383761Z",
     "shell.execute_reply": "2023-06-22T13:33:08.210994Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_oil(oil):\n",
    "    \"\"\"\n",
    "    Creation de statistiques et formations de features pour le CSV sur l'essence\n",
    "    \"\"\"\n",
    "    oil['month'] = oil['date'].dt.month\n",
    "    oil['month_avg'] = oil.groupby('month')['dcoilwtico'].transform('mean')\n",
    "\n",
    "    oil['tmp'] = oil['dcoilwtico'].map(np.isnan)\n",
    "    oil['month_avg'] = oil['tmp'] * oil['month_avg']\n",
    "    oil['month_avg'] = oil['month_avg'].astype(float)\n",
    "\n",
    "    oil['dcoilwtico'].fillna(0, inplace=True)\n",
    "    oil['dcoilwtico'] = oil['dcoilwtico'] + oil['month_avg']\n",
    "\n",
    "    oil = oil.drop(['month', 'month_avg', 'tmp'], axis=1)\n",
    "\n",
    "    return oil\n",
    "\n",
    "\n",
    "oil_df = preprocess_oil(oil_df)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:08.213388Z",
     "iopub.execute_input": "2023-06-22T13:33:08.213640Z",
     "iopub.status.idle": "2023-06-22T13:33:08.226266Z",
     "shell.execute_reply.started": "2023-06-22T13:33:08.213619Z",
     "shell.execute_reply": "2023-06-22T13:33:08.225447Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_holiday(df):\n",
    "    \"\"\"\n",
    "    Separation du CSV sur les événements en df de jours fériés/vacances, tremblement de terre et fêtes\n",
    "    \"\"\"\n",
    "    filtered_holiday = df[(df['transferred'] == False) & (df['holiday_type'] != 'Work Day')]\n",
    "\n",
    "    event = df[df['holiday_type'] == 'Event']\n",
    "    earthquake = event[event['description'].str.startswith('Terremoto Manabi')]\n",
    "    event = event[event['description'].str.startswith('Terremoto Manabi') == False]\n",
    "\n",
    "    return filtered_holiday, event, earthquake\n",
    "\n",
    "\n",
    "filtered_df, event_df, earthquake_df = preprocess_holiday(holidays_df)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:08.227378Z",
     "iopub.execute_input": "2023-06-22T13:33:08.227631Z",
     "iopub.status.idle": "2023-06-22T13:33:08.238138Z",
     "shell.execute_reply.started": "2023-06-22T13:33:08.227610Z",
     "shell.execute_reply": "2023-06-22T13:33:08.237254Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "event_df = event_df[['date', 'description']]\n",
    "event_df.rename({'description': 'event_name'}, axis=1, inplace=True)\n",
    "\n",
    "earthquake_df = earthquake_df[['date', 'description']]\n",
    "earthquake_df.rename({'description': 'earthquake'}, axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:08.239449Z",
     "iopub.execute_input": "2023-06-22T13:33:08.239681Z",
     "iopub.status.idle": "2023-06-22T13:33:08.255904Z",
     "shell.execute_reply.started": "2023-06-22T13:33:08.239661Z",
     "shell.execute_reply": "2023-06-22T13:33:08.255049Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Séparation en différentes échelles : locale, régionale et nationale\n",
    "\n",
    "h_local = filtered_df[filtered_df['locale'] == 'Local']\n",
    "h_local = h_local[['date', 'locale_name', 'description']]\n",
    "h_local = h_local.rename({'locale_name': 'city', 'description': 'local_hname'}, axis=1)\n",
    "\n",
    "h_regional = filtered_df[filtered_df['locale'] == 'Regional']\n",
    "h_regional = h_regional[['date', 'locale_name', 'description']]\n",
    "h_regional = h_regional.rename({'locale_name': 'state', 'description': 'regional_hname'}, axis=1)\n",
    "\n",
    "h_national = filtered_df[filtered_df['locale'] == 'National']\n",
    "h_national = h_national[['date', 'description']]\n",
    "h_national = h_national.rename({'description': 'national_hname'}, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:08.259247Z",
     "iopub.execute_input": "2023-06-22T13:33:08.259621Z",
     "iopub.status.idle": "2023-06-22T13:33:08.274276Z",
     "shell.execute_reply.started": "2023-06-22T13:33:08.259587Z",
     "shell.execute_reply": "2023-06-22T13:33:08.273457Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def merge_tables(df):\n",
    "    \"\"\"\n",
    "    Rassemblement de toutes les informations dans un seul Dataframe\n",
    "    \"\"\"\n",
    "    df = df.merge(oil_df, on='date', how='left')\n",
    "    df = df.merge(stores_df, on='store_nbr', how='left')\n",
    "\n",
    "    df = df.merge(event_df, on='date', how='left')\n",
    "    df = df.merge(earthquake_df, on='date', how='left')\n",
    "    df = df.merge(h_local, on=['date', 'city'], how='left')\n",
    "    df = df.merge(h_regional, on=['date', 'state'], how='left')\n",
    "    df = df.merge(h_national, on='date', how='left')\n",
    "\n",
    "    df = df.merge(transactions_df, on=['date', 'store_nbr'], how='left')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = merge_tables(train_df)\n",
    "test_df = merge_tables(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:08.275159Z",
     "iopub.execute_input": "2023-06-22T13:33:08.275426Z",
     "iopub.status.idle": "2023-06-22T13:33:22.368276Z",
     "shell.execute_reply.started": "2023-06-22T13:33:08.275399Z",
     "shell.execute_reply": "2023-06-22T13:33:22.366877Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# pour économiser de la mémoire\n",
    "del h_local, h_regional, h_national, earthquake_df, event_df, stores_df, oil_df, filtered_df, transactions_df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:22.369472Z",
     "iopub.execute_input": "2023-06-22T13:33:22.369762Z",
     "iopub.status.idle": "2023-06-22T13:33:22.374193Z",
     "shell.execute_reply.started": "2023-06-22T13:33:22.369738Z",
     "shell.execute_reply": "2023-06-22T13:33:22.373444Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def handle_na(df):\n",
    "    \"\"\"\n",
    "    Pour les features de type string\n",
    "    \"\"\"\n",
    "    obj_vals = ['event_name', 'earthquake', 'local_hname', 'regional_hname', 'national_hname']\n",
    "    df[obj_vals] = df[obj_vals].fillna('0')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = handle_na(train_df)\n",
    "test_df = handle_na(test_df)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:22.376392Z",
     "iopub.execute_input": "2023-06-22T13:33:22.376923Z",
     "iopub.status.idle": "2023-06-22T13:33:23.945088Z",
     "shell.execute_reply.started": "2023-06-22T13:33:22.376852Z",
     "shell.execute_reply": "2023-06-22T13:33:23.944149Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# encodage des deux critères de sous ensembles\n",
    "encode_cols = ['family', 'store_nbr']\n",
    "\n",
    "lb = LabelEncoder()\n",
    "\n",
    "for c in encode_cols:\n",
    "    train_df[c] = lb.fit_transform(train_df[c])\n",
    "    test_df[c] = lb.transform(test_df[c])\n",
    "\n",
    "del encode_cols, lb"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:23.946093Z",
     "iopub.execute_input": "2023-06-22T13:33:23.946336Z",
     "iopub.status.idle": "2023-06-22T13:33:24.603972Z",
     "shell.execute_reply.started": "2023-06-22T13:33:23.946299Z",
     "shell.execute_reply": "2023-06-22T13:33:24.602807Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# repère les produits non vendus par certains magasins afin de pouvoir adapter les prédictions\n",
    "\n",
    "df_zeros = train_df.groupby([\"store_nbr\", \"family\"]).sales.sum().reset_index()\n",
    "df_zeros = df_zeros[df_zeros.sales == 0]\n",
    "df_zeros = df_zeros.set_index(['store_nbr', 'family'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:24.607295Z",
     "iopub.execute_input": "2023-06-22T13:33:24.607605Z",
     "iopub.status.idle": "2023-06-22T13:33:24.726174Z",
     "shell.execute_reply.started": "2023-06-22T13:33:24.607579Z",
     "shell.execute_reply": "2023-06-22T13:33:24.725158Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# encodage du reste des features string/catégorique en one hot pour faciliter le traitement\n",
    "\n",
    "encode_cols = ['store_type', 'event_name', 'earthquake', 'city', 'cluster', 'state',\n",
    "               'local_hname', 'regional_hname', 'national_hname']\n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns=encode_cols)\n",
    "test_df = pd.get_dummies(test_df, columns=encode_cols)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:24.727759Z",
     "iopub.execute_input": "2023-06-22T13:33:24.728026Z",
     "iopub.status.idle": "2023-06-22T13:33:30.819165Z",
     "shell.execute_reply.started": "2023-06-22T13:33:24.728001Z",
     "shell.execute_reply": "2023-06-22T13:33:30.818085Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def optimize_mem(df, for_int=False):\n",
    "    \"\"\"\n",
    "    Convertit les valeurs dans le format le plus petit possible\n",
    "    :param for_int sert à éviter les unsigned, non acceptés par XGBoost\n",
    "    \"\"\"\n",
    "    gl_fl = df.select_dtypes(include=['float'])\n",
    "    df[gl_fl.columns] = gl_fl.apply(pd.to_numeric, downcast=\"float\")\n",
    "\n",
    "    gl_int = df.select_dtypes(include=['int'])\n",
    "    down_target = \"integer\" if for_int else \"unsigned\"\n",
    "\n",
    "    df[gl_int.columns] = gl_int.apply(pd.to_numeric, downcast=down_target)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:30.820408Z",
     "iopub.execute_input": "2023-06-22T13:33:30.820696Z",
     "iopub.status.idle": "2023-06-22T13:33:30.827057Z",
     "shell.execute_reply.started": "2023-06-22T13:33:30.820674Z",
     "shell.execute_reply": "2023-06-22T13:33:30.826002Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# on retient les ids pour un future split\n",
    "train_ids = train_df.id\n",
    "test_ids = test_df.id\n",
    "\n",
    "# on concatene tout pour faire les operations lags, rolling, etc\n",
    "all_data = pd.concat([train_df, test_df]).reset_index()\n",
    "all_data = optimize_mem(all_data)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:33:30.828588Z",
     "iopub.execute_input": "2023-06-22T13:33:30.828940Z",
     "iopub.status.idle": "2023-06-22T13:34:10.447585Z",
     "shell.execute_reply.started": "2023-06-22T13:33:30.828914Z",
     "shell.execute_reply": "2023-06-22T13:34:10.446524Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def lag_ft(df, lag_limit):\n",
    "    \"\"\"\n",
    "    Création des lags features\n",
    "    :param lag_limit sert à déterminer le nombre de lags à créer\n",
    "    \"\"\"\n",
    "    targets = ['sales', 'dcoilwtico', 'transactions']\n",
    "    keys = ['store_nbr', 'family']  # sert à limiter les statistiques au meme magasin & produit\n",
    "\n",
    "    lag_df = pd.DataFrame()\n",
    "    for target in targets:\n",
    "        for lag in range(1, lag_limit + 1):\n",
    "            lag_df[target + '_lag_' + str(lag)] = df.groupby(keys)[target].shift(lag)\n",
    "\n",
    "    return lag_df\n",
    "\n",
    "\n",
    "lag_df = lag_ft(all_data[['store_nbr', 'family', 'sales', 'dcoilwtico', 'transactions']], lag_limit=6)\n",
    "all_data = all_data.join(lag_df)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:34:10.467849Z",
     "iopub.execute_input": "2023-06-22T13:34:10.468262Z",
     "iopub.status.idle": "2023-06-22T13:34:13.503416Z",
     "shell.execute_reply.started": "2023-06-22T13:34:10.468236Z",
     "shell.execute_reply": "2023-06-22T13:34:13.502632Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_data = all_data.drop_duplicates(subset=['id'], keep='first')\n",
    "all_data = optimize_mem(all_data)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:34:13.504302Z",
     "iopub.execute_input": "2023-06-22T13:34:13.505326Z",
     "iopub.status.idle": "2023-06-22T13:34:36.631110Z",
     "shell.execute_reply.started": "2023-06-22T13:34:13.505289Z",
     "shell.execute_reply": "2023-06-22T13:34:36.629660Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_rolling_ft(new_df):\n",
    "    \"\"\"\n",
    "    Création de rolling features, avec average, min et max.\n",
    "    \"\"\"\n",
    "    targets = ['sales', 'dcoilwtico']\n",
    "    rollings = [3, 7, 14, 30]  # sert à limiter les statistiques au meme magasin & produit\n",
    "\n",
    "    shift_df = pd.DataFrame()\n",
    "\n",
    "    for target in targets:\n",
    "        print(f'Creating {target} features')\n",
    "        grouped = new_df.groupby([\"store_nbr\", \"family\"])[target]\n",
    "\n",
    "        for rollval in rollings:\n",
    "            results = {}\n",
    "\n",
    "            avg_roll = grouped.rolling(rollval).mean()\n",
    "            max_roll = grouped.rolling(rollval).max()\n",
    "            min_roll = grouped.rolling(rollval).min()\n",
    "\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag7_avg\"] = avg_roll.shift(7).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag7_max\"] = max_roll.shift(7).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag7_min\"] = min_roll.shift(7).values\n",
    "\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag30_avg\"] = avg_roll.shift(30).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag30_max\"] = max_roll.shift(30).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag30_min\"] = min_roll.shift(30).values\n",
    "\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag60_avg\"] = avg_roll.shift(60).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag60_max\"] = max_roll.shift(60).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag60_min\"] = min_roll.shift(60).values\n",
    "\n",
    "            result_df = pd.DataFrame.from_dict(results)\n",
    "            shift_df = pd.concat([shift_df, result_df], axis=1)\n",
    "\n",
    "        shift_df = optimize_mem(shift_df)\n",
    "\n",
    "    return shift_df\n",
    "\n",
    "\n",
    "print(\"Creating rolling features\")\n",
    "sort_df = all_data[[\"store_nbr\", \"family\", \"date\", 'sales', 'dcoilwtico']].sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "res_df = create_rolling_ft(sort_df)\n",
    "all_data = all_data.join(res_df)\n",
    "print('Out')"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:34:36.632679Z",
     "iopub.execute_input": "2023-06-22T13:34:36.633083Z",
     "iopub.status.idle": "2023-06-22T13:35:10.405668Z",
     "shell.execute_reply.started": "2023-06-22T13:34:36.633047Z",
     "shell.execute_reply": "2023-06-22T13:35:10.404266Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "text": "Creating rolling features\nCreating sales features\nCreating dcoilwtico features\nOut\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def create_smallrolling_ft(new_df):\n",
    "    \"\"\"\n",
    "    Même fonction mais avec moins de paramètres afin de ne pas surcharger la mémoire\n",
    "    \"\"\"\n",
    "    targets = ['transactions']\n",
    "    rollings = [3, 5, 7]\n",
    "\n",
    "    shift_df = pd.DataFrame()\n",
    "\n",
    "    for target in targets:\n",
    "        print(f'Creating {target} features')\n",
    "        grouped = new_df.groupby([\"store_nbr\", \"family\"])[target]\n",
    "\n",
    "        for rollval in rollings:\n",
    "            results = {}\n",
    "\n",
    "            avg_roll = grouped.rolling(rollval).mean()\n",
    "            max_roll = grouped.rolling(rollval).max()\n",
    "            min_roll = grouped.rolling(rollval).min()\n",
    "\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag7_avg\"] = avg_roll.shift(7).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag7_max\"] = max_roll.shift(7).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag7_min\"] = min_roll.shift(7).values\n",
    "\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag30_avg\"] = avg_roll.shift(30).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag30_max\"] = max_roll.shift(30).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag30_min\"] = min_roll.shift(30).values\n",
    "\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag60_avg\"] = avg_roll.shift(60).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag60_max\"] = max_roll.shift(60).values\n",
    "            results[f\"SMA{str(rollval)}_{target}_lag60_min\"] = min_roll.shift(60).values\n",
    "\n",
    "            result_df = pd.DataFrame.from_dict(results)\n",
    "            shift_df = pd.concat([shift_df, result_df], axis=1)\n",
    "\n",
    "        shift_df = optimize_mem(shift_df)\n",
    "\n",
    "    return shift_df\n",
    "\n",
    "\n",
    "print(\"Creating small rolling features\")\n",
    "sort_df = all_data[[\"store_nbr\", \"family\", \"date\", 'transactions']].sort_values([\"store_nbr\", \"family\", \"date\"])\n",
    "res_df = create_smallrolling_ft(sort_df)\n",
    "all_data = all_data.join(res_df)\n",
    "print('Out')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:35:10.407277Z",
     "iopub.execute_input": "2023-06-22T13:35:10.407664Z",
     "iopub.status.idle": "2023-06-22T13:35:20.149801Z",
     "shell.execute_reply.started": "2023-06-22T13:35:10.407636Z",
     "shell.execute_reply": "2023-06-22T13:35:20.148507Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": "Creating small rolling features\nCreating transactions features\nOut\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def create_exp_mov_av(df):\n",
    "    \"\"\"\n",
    "    Exponential moving average\n",
    "    \"\"\"\n",
    "    targets = ['sales', 'dcoilwtico', 'transactions']\n",
    "    span = [7, 16, 30, 60]\n",
    "\n",
    "    ewm_df = pd.DataFrame()\n",
    "\n",
    "    for target in targets:\n",
    "        print(f'Creating {target} features')\n",
    "        grouped = df.groupby([\"store_nbr\", \"family\"])[target]\n",
    "\n",
    "        for sp in span:\n",
    "            ewm_df[f'{target}_ewm_span_{sp}'] = grouped.ewm(span=sp).mean().values\n",
    "\n",
    "        ewm_df = optimize_mem(ewm_df)\n",
    "\n",
    "    return ewm_df\n",
    "\n",
    "\n",
    "print(\"Creating ewm features\")\n",
    "res_df = create_exp_mov_av(all_data[[\"store_nbr\", \"family\", 'sales', 'dcoilwtico', 'transactions']])\n",
    "all_data = all_data.join(res_df)\n",
    "print('Out')"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:35:20.151359Z",
     "iopub.execute_input": "2023-06-22T13:35:20.151941Z",
     "iopub.status.idle": "2023-06-22T13:35:34.455110Z",
     "shell.execute_reply.started": "2023-06-22T13:35:20.151918Z",
     "shell.execute_reply": "2023-06-22T13:35:34.454081Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": "Creating ewm features\nCreating sales features\nCreating dcoilwtico features\nCreating transactions features\nOut\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# sert à économiser de la mémoire\n",
    "del res_df, lag_df, sort_df"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:35:34.456380Z",
     "iopub.execute_input": "2023-06-22T13:35:34.457399Z",
     "iopub.status.idle": "2023-06-22T13:35:34.468635Z",
     "shell.execute_reply.started": "2023-06-22T13:35:34.457369Z",
     "shell.execute_reply": "2023-06-22T13:35:34.467618Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_data = all_data.sort_values(['id'])\n",
    "all_data = all_data.fillna(0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:35:34.470166Z",
     "iopub.execute_input": "2023-06-22T13:35:34.470457Z",
     "iopub.status.idle": "2023-06-22T13:35:39.733275Z",
     "shell.execute_reply.started": "2023-06-22T13:35:34.470432Z",
     "shell.execute_reply": "2023-06-22T13:35:39.732093Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "all_data = optimize_mem(all_data, for_int=True)  # formattage pour XGBoost"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:35:39.738909Z",
     "iopub.execute_input": "2023-06-22T13:35:39.739238Z",
     "iopub.status.idle": "2023-06-22T13:36:34.982784Z",
     "shell.execute_reply.started": "2023-06-22T13:35:39.739216Z",
     "shell.execute_reply": "2023-06-22T13:36:34.981775Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def split_dfs(df):\n",
    "    new_train = df[df['id'].isin(train_ids)]\n",
    "    new_test = df[df['id'].isin(test_ids)]\n",
    "\n",
    "    return new_train, new_test\n",
    "\n",
    "\n",
    "train_df, test_df = split_dfs(all_data)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:36:34.984089Z",
     "iopub.execute_input": "2023-06-22T13:36:34.984378Z",
     "iopub.status.idle": "2023-06-22T13:36:38.175003Z",
     "shell.execute_reply.started": "2023-06-22T13:36:34.984354Z",
     "shell.execute_reply": "2023-06-22T13:36:38.174034Z"
    },
    "trusted": true
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "del all_data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:36:38.176083Z",
     "iopub.execute_input": "2023-06-22T13:36:38.176398Z",
     "iopub.status.idle": "2023-06-22T13:36:38.187455Z",
     "shell.execute_reply.started": "2023-06-22T13:36:38.176373Z",
     "shell.execute_reply": "2023-06-22T13:36:38.186107Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def train_model(train, y):\n",
    "    temp_train = train.copy()\n",
    "\n",
    "    # exemple de sous grille utilisée\n",
    "    grid_params = {\n",
    "        'max_depth': [6, 8],\n",
    "        'learning_rate': [0.3, 0.03],\n",
    "    }\n",
    "\n",
    "    # métriques personnalisées pour aider le GridSearch à évaluer la performance\n",
    "    scoring = {\n",
    "        \"mae\": make_scorer(mean_absolute_error),\n",
    "        \"r2\": make_scorer(r2_score)\n",
    "    }\n",
    "\n",
    "    _, x_v, _, y_v = train_test_split(temp_train, y, train_size=split_size, random_state=42, shuffle=False)\n",
    "\n",
    "    model = xgb.XGBRegressor(importance_type='gain', verbosity=1, eval_metric='rmse',\n",
    "                             objective='reg:squarederror', random_state=42)\n",
    "\n",
    "    clf = GridSearchCV(model, grid_params, refit='r2', scoring=scoring, error_score='raise', verbose=1, n_jobs=1, cv=3)\n",
    "    clf.fit(temp_train, y)\n",
    "\n",
    "    print(clf.best_score_)\n",
    "    print(clf.best_params_)\n",
    "\n",
    "    return clf.best_estimator_, x_v, y_v\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:36:38.204592Z",
     "iopub.execute_input": "2023-06-22T13:36:38.204895Z",
     "iopub.status.idle": "2023-06-22T13:36:38.215406Z",
     "shell.execute_reply.started": "2023-06-22T13:36:38.204870Z",
     "shell.execute_reply": "2023-06-22T13:36:38.214090Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "split_size = 0.8\n",
    "drop_cols = ['id', 'date', 'sales']\n",
    "print(\"Starting training phase\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:36:38.243632Z",
     "iopub.execute_input": "2023-06-22T13:36:38.243874Z",
     "iopub.status.idle": "2023-06-22T13:36:38.257294Z",
     "shell.execute_reply.started": "2023-06-22T13:36:38.243849Z",
     "shell.execute_reply": "2023-06-22T13:36:38.256266Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": "Starting training phase\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def show_metrics(actual, predictions, mdict):\n",
    "    \"\"\"\n",
    "    Résumé des métriques de regression\n",
    "    Si un dict est passé en paramètres, l'alimente [sert au récap des entraînements des ensembles]\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(actual, predictions)\n",
    "    mse = mean_squared_error(actual, predictions, squared=True)\n",
    "    rmsle = mean_squared_log_error(actual, predictions)\n",
    "    r2 = r2_score(actual, predictions)\n",
    "\n",
    "    print(\"\\nRegression metrics\")\n",
    "    print('MAE: {:.2f}'.format(mae))\n",
    "    print('MSE: {:.2f}'.format(mse))\n",
    "    print('RMSLE: {:.2f}'.format(rmsle))\n",
    "    print('R2: {:.2f}'.format(r2))\n",
    "\n",
    "    if mdict is not None:\n",
    "        mdict[\"mae\"].append(mae)\n",
    "        mdict[\"mse\"].append(mse)\n",
    "        mdict[\"rmsle\"].append(rmsle)\n",
    "        mdict[\"r2\"].append(r2)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:36:38.258467Z",
     "iopub.execute_input": "2023-06-22T13:36:38.258763Z",
     "iopub.status.idle": "2023-06-22T13:36:38.269490Z",
     "shell.execute_reply.started": "2023-06-22T13:36:38.258735Z",
     "shell.execute_reply": "2023-06-22T13:36:38.268393Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# préparation des structs de données et variables pour entraîner l'ensemble par magasins\n",
    "\n",
    "shop_preprocess = [None] * nb_stores\n",
    "shop_models = [None] * nb_stores\n",
    "\n",
    "shop_drop_cols = drop_cols.copy()\n",
    "shop_drop_cols.append('store_nbr')\n",
    "\n",
    "dropped_df = train_df.drop(shop_drop_cols, axis=1)\n",
    "shop_features = dropped_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:36:38.270917Z",
     "iopub.execute_input": "2023-06-22T13:36:38.271219Z",
     "iopub.status.idle": "2023-06-22T13:36:38.754381Z",
     "shell.execute_reply.started": "2023-06-22T13:36:38.271196Z",
     "shell.execute_reply": "2023-06-22T13:36:38.753503Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "del dropped_df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-22T13:36:38.755491Z",
     "iopub.execute_input": "2023-06-22T13:36:38.755714Z",
     "iopub.status.idle": "2023-06-22T13:36:38.765105Z",
     "shell.execute_reply.started": "2023-06-22T13:36:38.755695Z",
     "shell.execute_reply": "2023-06-22T13:36:38.764049Z"
    },
    "trusted": true
   },
   "execution_count": 38,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "metrics_dict = {\"mae\": [], \"mse\": [], \"rmsle\": [], \"r2\": []}  # dict pour récap de l'entraînement\n",
    "\n",
    "for shop in range(nb_stores):\n",
    "    shop_df = train_df[train_df.store_nbr == shop]  # isolation des données par magasin\n",
    "    shop_y = shop_df['sales']  # target\n",
    "\n",
    "    print(f\"Training model {shop}...\")\n",
    "    shopmodel, x_val, y_val, pipe = train_model(shop_df[shop_features], shop_y)\n",
    "\n",
    "    shop_preprocess[shop] = pipe  # on garde la pipeline utilisée pour l'utiliser lors des soumissions\n",
    "\n",
    "    print(f\"\\nEvaluating sub-model {shop}\")\n",
    "    y_pred = shopmodel.predict(x_val)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "\n",
    "    shop_models[shop] = shopmodel  # on retient le modèle entraîné\n",
    "\n",
    "    show_metrics(y_val, y_pred, metrics_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "execution": {
     "iopub.status.busy": "2023-06-22T13:38:55.225476Z",
     "iopub.execute_input": "2023-06-22T13:38:55.225828Z",
     "iopub.status.idle": "2023-06-22T13:39:36.258610Z",
     "shell.execute_reply.started": "2023-06-22T13:38:55.225801Z",
     "shell.execute_reply": "2023-06-22T13:39:36.257696Z"
    },
    "trusted": true
   },
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "text": "Training model 0...\n[0]\tvalidation_0-rmse:781.29722\n[1]\tvalidation_0-rmse:774.30690\n[2]\tvalidation_0-rmse:753.44483\n[3]\tvalidation_0-rmse:733.79623\n[4]\tvalidation_0-rmse:713.60447\n[5]\tvalidation_0-rmse:694.83261\n[6]\tvalidation_0-rmse:676.70187\n[7]\tvalidation_0-rmse:658.17488\n[8]\tvalidation_0-rmse:640.80318\n[9]\tvalidation_0-rmse:624.26645\n[10]\tvalidation_0-rmse:608.12385\n[11]\tvalidation_0-rmse:592.41747\n[12]\tvalidation_0-rmse:577.02432\n[13]\tvalidation_0-rmse:561.52218\n[14]\tvalidation_0-rmse:547.45424\n[15]\tvalidation_0-rmse:533.75601\n[16]\tvalidation_0-rmse:520.19006\n[17]\tvalidation_0-rmse:507.23190\n[18]\tvalidation_0-rmse:494.01611\n[19]\tvalidation_0-rmse:483.78111\n[20]\tvalidation_0-rmse:471.72350\n[21]\tvalidation_0-rmse:460.20234\n[22]\tvalidation_0-rmse:449.12273\n[23]\tvalidation_0-rmse:438.39335\n[24]\tvalidation_0-rmse:427.70650\n[25]\tvalidation_0-rmse:417.05566\n[26]\tvalidation_0-rmse:407.02552\n[27]\tvalidation_0-rmse:396.98730\n[28]\tvalidation_0-rmse:387.93513\n[29]\tvalidation_0-rmse:378.43134\n[30]\tvalidation_0-rmse:368.87015\n[31]\tvalidation_0-rmse:360.54598\n[32]\tvalidation_0-rmse:352.13113\n[33]\tvalidation_0-rmse:344.46126\n[34]\tvalidation_0-rmse:336.42858\n[35]\tvalidation_0-rmse:329.52517\n[36]\tvalidation_0-rmse:322.43867\n[37]\tvalidation_0-rmse:315.70893\n[38]\tvalidation_0-rmse:309.29558\n[39]\tvalidation_0-rmse:303.49525\n[40]\tvalidation_0-rmse:297.05833\n[41]\tvalidation_0-rmse:291.18992\n[42]\tvalidation_0-rmse:285.48707\n[43]\tvalidation_0-rmse:279.02126\n[44]\tvalidation_0-rmse:273.16370\n[45]\tvalidation_0-rmse:267.63123\n[46]\tvalidation_0-rmse:262.87118\n[47]\tvalidation_0-rmse:258.27712\n[48]\tvalidation_0-rmse:253.63447\n[49]\tvalidation_0-rmse:249.04031\n[50]\tvalidation_0-rmse:243.95261\n[51]\tvalidation_0-rmse:243.49156\n[52]\tvalidation_0-rmse:238.64966\n[53]\tvalidation_0-rmse:234.02156\n[54]\tvalidation_0-rmse:230.20218\n[55]\tvalidation_0-rmse:226.29473\n[56]\tvalidation_0-rmse:222.31204\n[57]\tvalidation_0-rmse:218.34551\n[58]\tvalidation_0-rmse:214.92759\n[59]\tvalidation_0-rmse:211.56465\n[60]\tvalidation_0-rmse:207.92065\n[61]\tvalidation_0-rmse:204.50453\n[62]\tvalidation_0-rmse:201.41621\n[63]\tvalidation_0-rmse:198.52803\n[64]\tvalidation_0-rmse:195.84916\n[65]\tvalidation_0-rmse:192.56664\n[66]\tvalidation_0-rmse:190.20226\n[67]\tvalidation_0-rmse:187.59538\n[68]\tvalidation_0-rmse:185.25995\n[69]\tvalidation_0-rmse:182.74892\n[70]\tvalidation_0-rmse:180.59852\n[71]\tvalidation_0-rmse:178.08567\n[72]\tvalidation_0-rmse:175.34221\n[73]\tvalidation_0-rmse:173.61133\n[74]\tvalidation_0-rmse:171.77620\n[75]\tvalidation_0-rmse:169.81945\n[76]\tvalidation_0-rmse:168.32851\n[77]\tvalidation_0-rmse:166.06572\n[78]\tvalidation_0-rmse:164.39617\n[79]\tvalidation_0-rmse:163.05078\n[80]\tvalidation_0-rmse:162.87261\n[81]\tvalidation_0-rmse:161.31096\n[82]\tvalidation_0-rmse:159.82931\n[83]\tvalidation_0-rmse:158.23498\n[84]\tvalidation_0-rmse:156.99974\n[85]\tvalidation_0-rmse:155.81084\n[86]\tvalidation_0-rmse:154.73799\n[87]\tvalidation_0-rmse:153.87294\n[88]\tvalidation_0-rmse:152.50883\n[89]\tvalidation_0-rmse:151.24732\n[90]\tvalidation_0-rmse:150.37786\n[91]\tvalidation_0-rmse:149.42216\n[92]\tvalidation_0-rmse:148.44716\n[93]\tvalidation_0-rmse:147.64230\n[94]\tvalidation_0-rmse:146.71508\n[95]\tvalidation_0-rmse:145.98262\n[96]\tvalidation_0-rmse:145.19871\n[97]\tvalidation_0-rmse:144.45648\n[98]\tvalidation_0-rmse:144.03896\n[99]\tvalidation_0-rmse:143.34504\n[100]\tvalidation_0-rmse:142.63397\n[101]\tvalidation_0-rmse:142.15550\n[102]\tvalidation_0-rmse:141.38912\n[103]\tvalidation_0-rmse:140.83322\n[104]\tvalidation_0-rmse:140.46357\n[105]\tvalidation_0-rmse:139.85705\n[106]\tvalidation_0-rmse:138.93138\n[107]\tvalidation_0-rmse:138.36983\n[108]\tvalidation_0-rmse:137.89423\n[109]\tvalidation_0-rmse:137.26600\n[110]\tvalidation_0-rmse:136.55554\n[111]\tvalidation_0-rmse:135.60935\n[112]\tvalidation_0-rmse:135.24660\n[113]\tvalidation_0-rmse:134.77863\n[114]\tvalidation_0-rmse:134.60778\n[115]\tvalidation_0-rmse:134.31455\n[116]\tvalidation_0-rmse:133.84497\n[117]\tvalidation_0-rmse:133.43824\n[118]\tvalidation_0-rmse:132.97910\n[119]\tvalidation_0-rmse:132.64011\n[120]\tvalidation_0-rmse:132.35163\n[121]\tvalidation_0-rmse:132.00392\n[122]\tvalidation_0-rmse:131.61154\n[123]\tvalidation_0-rmse:131.05353\n[124]\tvalidation_0-rmse:130.69972\n[125]\tvalidation_0-rmse:130.25538\n[126]\tvalidation_0-rmse:129.89265\n[127]\tvalidation_0-rmse:129.44730\n[128]\tvalidation_0-rmse:129.12502\n[129]\tvalidation_0-rmse:128.81015\n[130]\tvalidation_0-rmse:128.43426\n[131]\tvalidation_0-rmse:128.26091\n[132]\tvalidation_0-rmse:127.91776\n[133]\tvalidation_0-rmse:127.61543\n[134]\tvalidation_0-rmse:127.41573\n[135]\tvalidation_0-rmse:126.94554\n[136]\tvalidation_0-rmse:126.70018\n[137]\tvalidation_0-rmse:126.50916\n[138]\tvalidation_0-rmse:126.37257\n[139]\tvalidation_0-rmse:126.27091\n[140]\tvalidation_0-rmse:126.09733\n[141]\tvalidation_0-rmse:125.80992\n[142]\tvalidation_0-rmse:125.59756\n[143]\tvalidation_0-rmse:125.26829\n[144]\tvalidation_0-rmse:125.13274\n[145]\tvalidation_0-rmse:125.02815\n[146]\tvalidation_0-rmse:124.75723\n[147]\tvalidation_0-rmse:124.49117\n[148]\tvalidation_0-rmse:124.26266\n[149]\tvalidation_0-rmse:124.02511\n[150]\tvalidation_0-rmse:123.98571\n[151]\tvalidation_0-rmse:123.77786\n[152]\tvalidation_0-rmse:123.65543\n[153]\tvalidation_0-rmse:123.50782\n[154]\tvalidation_0-rmse:123.40661\n[155]\tvalidation_0-rmse:123.22285\n[156]\tvalidation_0-rmse:123.13367\n[157]\tvalidation_0-rmse:123.05744\n[158]\tvalidation_0-rmse:122.93041\n[159]\tvalidation_0-rmse:122.88980\n[160]\tvalidation_0-rmse:122.73677\n[161]\tvalidation_0-rmse:122.69086\n[162]\tvalidation_0-rmse:122.59717\n[163]\tvalidation_0-rmse:122.54960\n[164]\tvalidation_0-rmse:122.43192\n[165]\tvalidation_0-rmse:122.27335\n[166]\tvalidation_0-rmse:122.22042\n[167]\tvalidation_0-rmse:121.56915\n[168]\tvalidation_0-rmse:121.53941\n[169]\tvalidation_0-rmse:121.52591\n[170]\tvalidation_0-rmse:121.30857\n[171]\tvalidation_0-rmse:121.21902\n[172]\tvalidation_0-rmse:121.15701\n[173]\tvalidation_0-rmse:121.08084\n[174]\tvalidation_0-rmse:120.97257\n[175]\tvalidation_0-rmse:120.95347\n[176]\tvalidation_0-rmse:120.95959\n[177]\tvalidation_0-rmse:120.85227\n[178]\tvalidation_0-rmse:120.73379\n[179]\tvalidation_0-rmse:120.70521\n[180]\tvalidation_0-rmse:120.58612\n[181]\tvalidation_0-rmse:120.54920\n[182]\tvalidation_0-rmse:120.44282\n[183]\tvalidation_0-rmse:120.35092\n[184]\tvalidation_0-rmse:120.25100\n[185]\tvalidation_0-rmse:120.22766\n[186]\tvalidation_0-rmse:120.13102\n[187]\tvalidation_0-rmse:120.06185\n[188]\tvalidation_0-rmse:120.03324\n[189]\tvalidation_0-rmse:119.95293\n[190]\tvalidation_0-rmse:119.93497\n[191]\tvalidation_0-rmse:119.76780\n[192]\tvalidation_0-rmse:119.62283\n[193]\tvalidation_0-rmse:119.76586\n[194]\tvalidation_0-rmse:119.66845\n[195]\tvalidation_0-rmse:119.70006\n[196]\tvalidation_0-rmse:119.61048\n[197]\tvalidation_0-rmse:119.53780\n[198]\tvalidation_0-rmse:119.63916\n[199]\tvalidation_0-rmse:119.57799\n[200]\tvalidation_0-rmse:119.46375\n[201]\tvalidation_0-rmse:119.38726\n[202]\tvalidation_0-rmse:119.32612\n[203]\tvalidation_0-rmse:119.32558\n[204]\tvalidation_0-rmse:119.31067\n[205]\tvalidation_0-rmse:119.26389\n[206]\tvalidation_0-rmse:119.23855\n[207]\tvalidation_0-rmse:119.18330\n[208]\tvalidation_0-rmse:119.13712\n[209]\tvalidation_0-rmse:119.03351\n[210]\tvalidation_0-rmse:119.00179\n[211]\tvalidation_0-rmse:119.06329\n[212]\tvalidation_0-rmse:118.99178\n[213]\tvalidation_0-rmse:118.93248\n[214]\tvalidation_0-rmse:118.91147\n[215]\tvalidation_0-rmse:118.80869\n[216]\tvalidation_0-rmse:118.72162\n[217]\tvalidation_0-rmse:118.71681\n[218]\tvalidation_0-rmse:118.73100\n[219]\tvalidation_0-rmse:118.72084\n[220]\tvalidation_0-rmse:118.70585\n[221]\tvalidation_0-rmse:118.70568\n[222]\tvalidation_0-rmse:118.60739\n[223]\tvalidation_0-rmse:118.59093\n[224]\tvalidation_0-rmse:118.59071\n[225]\tvalidation_0-rmse:118.49729\n[226]\tvalidation_0-rmse:118.56822\n[227]\tvalidation_0-rmse:118.48153\n[228]\tvalidation_0-rmse:118.47050\n[229]\tvalidation_0-rmse:118.46664\n[230]\tvalidation_0-rmse:118.45170\n[231]\tvalidation_0-rmse:118.41785\n[232]\tvalidation_0-rmse:118.38918\n[233]\tvalidation_0-rmse:118.38806\n[234]\tvalidation_0-rmse:118.47508\n[235]\tvalidation_0-rmse:118.51581\n[236]\tvalidation_0-rmse:118.51270\n[237]\tvalidation_0-rmse:118.46384\n[238]\tvalidation_0-rmse:118.46094\n[239]\tvalidation_0-rmse:118.47737\n[240]\tvalidation_0-rmse:118.46059\n[241]\tvalidation_0-rmse:118.44071\n[242]\tvalidation_0-rmse:118.43302\n[243]\tvalidation_0-rmse:118.40845\n[244]\tvalidation_0-rmse:118.38729\n[245]\tvalidation_0-rmse:118.38393\n[246]\tvalidation_0-rmse:118.36329\n[247]\tvalidation_0-rmse:118.34549\n[248]\tvalidation_0-rmse:118.32852\n[249]\tvalidation_0-rmse:118.32030\n\nEvaluating sub-model 0\n\nRegression metrics\nMAE: 49.18\nMSE: 13998.65\nRMSLE: 1.19\nR2: 0.97\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"\\nBy shop training summary\")\n",
    "for mkey, mval in metrics_dict.items():\n",
    "    print(\"Average {} : {:.2f}\".format(mkey.upper(), mean(mval)))"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "execution": {
     "iopub.status.busy": "2023-06-22T13:41:36.877339Z",
     "iopub.execute_input": "2023-06-22T13:41:36.877769Z",
     "iopub.status.idle": "2023-06-22T13:41:36.884909Z",
     "shell.execute_reply.started": "2023-06-22T13:41:36.877733Z",
     "shell.execute_reply": "2023-06-22T13:41:36.883575Z"
    },
    "trusted": true
   },
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "text": "\nBy shop training summary\nAverage MAE : 49.18\nAverage MSE : 13998.65\nAverage RMSLE : 1.19\nAverage R2 : 0.97\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "del shop_models, shop_preprocess, shop_features"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# préparation des structs de données et variables pour entraîner l'ensemble par familles de produits\n",
    "\n",
    "family_preprocess = [None] * nb_families\n",
    "family_models = [None] * nb_families\n",
    "\n",
    "fam_drop_cols = drop_cols.copy()\n",
    "fam_drop_cols.append('family')\n",
    "\n",
    "dropped_df = train_df.drop(fam_drop_cols, axis=1)\n",
    "fam_features = dropped_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "del dropped_df"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "metrics_dict = {\"mae\": [], \"mse\": [], \"rmsle\": [], \"r2\": []}\n",
    "\n",
    "for fam in range(nb_families):\n",
    "    fam_df = train_df[train_df.family == fam]  # isolation des données par famille\n",
    "    family_y = fam_df['sales']\n",
    "\n",
    "    print(f\"Training model {fam}...\")\n",
    "    fammodel, x_val, y_val, pipe = train_model(fam_df[fam_features], family_y)\n",
    "\n",
    "    family_preprocess[fam] = pipe\n",
    "\n",
    "    print(f\"\\nEvaluating sub-model {fam}\")\n",
    "    y_pred = fammodel.predict(x_val)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "\n",
    "    family_models[fam] = fammodel\n",
    "\n",
    "    show_metrics(y_val, y_pred, metrics_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"\\nBy family training summary\")\n",
    "for mkey, mval in metrics_dict.items():\n",
    "    print(\"Average {} : {:.2f}\".format(mkey.upper(), mean(mval)))"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print('Notebook done')\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
